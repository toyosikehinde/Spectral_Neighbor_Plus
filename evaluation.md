# Evaluation of Lyrical Semantic Features in Spectral Neighbor Plus

This document describes the evaluation methods used to measure how the addition of lyrical semantic features influences the behavior and quality of the Spectral Neighbor Plus recommender. The goal of this first evaluation pass is to establish interpretable, lexicon-based metrics that reveal whether lyrics meaningfully improve neighborhood coherence when fused with spectral audio features.

The evaluation focuses on two complementary measures. The first assesses thematic consistency using simple keyword-based theme lexicons. The second examines emotional alignment through a lightweight valence score derived from positive and negative lexical indicators. Although these methods are intentionally simple, they provide a transparent foundation for analyzing the impact of lyrical semantics before introducing more advanced deep-learning or sentiment tools.

---

## 1. Evaluation Goals

The primary aim is to determine whether incorporating textual information from lyrics improves the structure of similarity neighborhoods generated by the recommender. Specifically, the evaluation examines whether tracks with similar dominant lyrical themes tend to cluster together after fusion, whether emotional tone remains stable across top-K neighbors, and whether the combined audio–lyrics similarity space captures both sound-based and meaning-based associations.

These evaluations also establish a baseline for future ethical and adversarial analyses by clarifying how textual content influences recommendations.

---

## 2. Theme Tags and Theme Purity@K

The first and primary metric, Theme Purity@K, assesses whether the neighbors recommended for a seed track share the same central lyrical theme.

### 2.1 Theme Lexicons

A set of compact, human-interpretable theme buckets is defined. Each theme consists of a short list of indicative keywords:

**[love]**  
love, heart, miss, together, kiss, feel, forever

**[heartbreak]**  
alone, cry, broken, leaving, goodbye

**[party]**  
club, dance, drink, tonight, party, floor

**[flex]**  
money, chain, drip, ice, foreign, vip

**[spiritual]**  
God, faith, pray, heaven, grace

These lexicons can be refined or expanded in future versions, but they provide a sufficient basis for broad semantic categorization.

### 2.2 Theme Vector Construction

For each track with available lyrics, the cleaned lyric text is tokenized and scanned for occurrences of the theme keywords. A theme vector is constructed by counting how many times words from each theme appear. The dominant theme is the theme with the highest count. Tracks with no meaningful matches are labeled as having no dominant theme and are excluded from theme-based evaluation.

### 2.3 Calculating Theme Purity@K

For each seed track:

1. Retrieve the top-K neighbors using the combined audio+lyrics similarity model.  
2. For every neighbor with a defined dominant theme, compare it to the seed’s theme.  
3. Compute:

\[
\text{ThemePurity@K} =
\frac{\text{Number of neighbors with same dominant theme as seed}}
{\text{Number of neighbors with a non-null theme}}
\]

A higher Theme Purity@K score indicates stronger thematic coherence within the recommended neighborhood. Because the metric is intuitive and directly linked to lyrical meaning, it serves as the core measure for evaluating the impact of lyrical semantics.

---

## 3. Valence Drift (Optional Add-On Metric)

While Theme Purity evaluates thematic alignment, valence examines the emotional tone of recommended neighbors.

### 3.1 Valence Lexicon

Two small lexicons represent positive and negative emotional indicators.

**Positive words**  
happy, joy, smile, blessed, free, strong, better

**Negative words**  
sad, cry, hurt, pain, broken, anxious, lost

These lists approximate emotional content in a simple and interpretable way.

### 3.2 Valence Score Calculation

For each track:

\[
\text{valence} =
\frac{\text{positive word count} - \text{negative word count}}
{\text{total emotional words}}
\]

A positive value reflects a more upbeat emotional tone while a negative value suggests sadness or emotional tension. Tracks with no emotional words receive a neutral valence of zero.

### 3.3 Valence Drift@K

For each seed track:

1. Retrieve the top-K neighbors.  
2. Compute the absolute difference in valence between the seed and each neighbor.  
3. Calculate the mean difference:

\[
\text{ValenceDrift@K} =
\frac{1}{K}\sum_{i=1}^{K} \left| v_{\text{seed}} - v_{\text{neighbor}_i} \right|
\]

Lower values indicate stronger emotional consistency across recommendations.

---

## 4. Interpretation of Results

Together, Theme Purity@K and Valence Drift@K offer a multi-dimensional framework for evaluating lyrical semantics. Higher Theme Purity scores demonstrate that the fused model captures themes expressed in lyrics, not only acoustic similarity. Lower Valence Drift suggests that emotional tone is preserved within recommended sets of songs. Comparing audio-only and audio+lyrics results quantifies how textual information reshapes neighborhood structure.

These early metrics provide a clear baseline before implementing more advanced techniques such as topic models, deep semantic embeddings, or transformer-based lyric encoders.

---

## 5. Future Extensions

This evaluation framework can be expanded in several directions, including:

• Deriving theme clusters using unsupervised topic modeling or embedding-space clustering.  
• Using pretrained sentiment or emotion models for richer valence–arousal analysis.  
• Conducting ethical-risk and adversarial testing by injecting specific lyric patterns, emotional shifts, or targeted keyword manipulations.  

These extensions will support deeper work on the robustness, fairness, and interpretability of multimodal recommendation systems.

---
